{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Starting-Explanation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM+t7j3oDehOl4KEdO+vHDU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yuAjUP2w_Mfy"},"source":["# **1. Rate vs. Spike**"]},{"cell_type":"markdown","metadata":{"id":"ACi83xmtRMK9"},"source":["## Rate-based Models\n","\n","Artificial Neural Networks (ANNs, or DNNs in the \"deep\", multi-layered form) are computing systems widely used in Artificial Intelligence (AI) applications. The computational units (the nodes) of these networks are inspired by the standard rate-based neural models commonly adopted by the neuroscience community to simulate and study complex network activities. In the steady-state assumption (the internal dynamics of neurons and synapses are not considered) a simple equation describes the relationship between the continuous-valued output $y$ of the neuron and its inputs:\n","\n","$$y = f(\\sum_i w_i \\cdot x_i + b)$$\n","\n","where $x_i$ are the inputs, $w_i$ their weights, $b$ the bias and $f$ is typically a non-linear activation function such as a *sigmoid* or *hyperbolic tangent* function.\n","\n","<center><div>\n","    <img src=\"https://c.mql5.com/2/35/artificialneuron__1.gif\" width = 500/>\n","</div></center>\n","\n","**In ANNs the output is a continuous value depending only on the instantaneous inputs. The neuron does not have an internal state affecting its output and no dynamics is considered.**\n","\n","Despite their use for AI, where inputs and outputs have different interpretations according to the specific applications, from a neuroscience perspective both inputs and outputs are represented by neuronal instantaneous firing rates. As a matter of fact, according to this classical view of neural computation, the atom of information and computation is the amplitude of the **firing rate**, not the individual spikes. In particular, the **precise timing** of spikes has little relevance in this view. In contrast, a number of scientists have argued that neural computation critically relies on the temporal coordination of spikes. This debate originates by the fact that both spike timing and rate information can be drawn from the spike trains outputted by biological neurons: spike timing is what defines pulse trains, whereas rate is an abstract mathematical construction on spike trains."]},{"cell_type":"markdown","metadata":{"id":"Rd_kESavRRzS"},"source":["## Spiking Models\n","This is where spiking neurons come into play. Spiking neural networks (or SNNs) are considered to be the third generation of neural networks for AI, preceeded by McCulloch-Pitts threshold neurons (\"first generation\") and Artificial Neural Networks with continuous activation functions (\"second generation\"). Among these network models, SNNs are the most biologically realistic ones, as information processing in such computational primitives is directly inspired by biological systems. Here information is encoded in spike trains, i.e. sequences of pulses (discrete, all-or-none events) with precise timing.\n","\n","<center><img src=\"https://miro.medium.com/max/2304/1*MQjX5_S8G2zVEQBd_DrJHg.png\" width=800></center>\n","\n","**SNNs include explicit temporal dynamics, add an additional dependence on the current state (membrane potential) of the neuron, and communicate with each other using spikes.**\n","\n","Biological neurons have been observed to produce sudden and short increases in voltage: spikes. The spike causes a charge to be transferred across the synapse between neurons. The charge from all the presynaptic neurons connected to a postsynaptic neuron builds up, until that neuron releases the charge itself in the form of a spike. The spike travels down the axon of the neuron arriving, after some delay, at the synapses of that neuron, causing charge to be passed forward to the next neuron. And the process repeats. The charge can result in either an excitatory response, in which the membrane voltage of the postsynaptic neuron increases or an inhibitory response, in which the membrane voltage of the postsynaptic neuron decreases as a result of the spike. Therefore SNNs have a dependence on the current state of the neurons, including explicit temporal dynamics describing the evolution of the process."]},{"cell_type":"markdown","metadata":{"id":"deYbWbRPVhQO"},"source":["# **2. Leaky Integrate and Fire (LIF)**"]},{"cell_type":"markdown","metadata":{"id":"A8XK3Kvi_UT9"},"source":["## Internal dynamics\n","One of the simplest (yet flexible) models of spiking neurons is the Leaky Integrate and Fire (LIF) neuron model. Here, the state of the neuron at any time, known as the **membrane potential** $u(t)$, depends on its previous state in addition to its current inputs. The dynamics of this state can be described as follows (note that we now have an explicit notion of time):\n","\n","$$\\tau_m \\cdot d{u}/dt = - [u(t) - u_{rest}] + R \\cdot i(t)$$\n","\n","where $\\tau_m$ is the membrane time constant, which determines how much the neuron depends on its previous states and inputs (therefore defines the neuron's memory), $u_{rest}$ is the membrane potential in the resting state and $i(t)$ is an input current. This linear differential equation describes the dynamics of a system with *leaky* behavior, i.e. for which the membrane potential $u$ slowly *leaks* (decays) to $u_{rest}$. This is why the neuron model is referred to as a Leaky Integrate and Fire model. As an example of leakage, see the evolution of the membrane voltage - in panel C of the following figure - when the input current is too low for the neuron to fire a spike (e.g. first step current on the left):\n","\n","\n","<center><img src=\"https://www.researchgate.net/profile/Filip_Ponulak/publication/221740684/figure/fig1/AS:305454820413441@1449837512055/Time-course-of-the-membrane-potential-ut-of-a-leaky-integrate-and-fire-neuron-LIF.png\" width=600><br /> <i>The time course of the membrane potential $u(t)$ of a LIF neuron (C) when driven by a current $i(t)$ is shown. The current can be either externally injected (A) or induced by the dynamics of a synapse in response to a presynaptic spike train (B). Initially, the state $u(t)$ of the LIF neuron is at the resting value $u_{rest}$ and the input current increases the membrane potential towards the firing threshold θ. Whenever the threshold is crossed the neuron emits a spike and the membrane voltage $u(t)$ is reset to a new value - here assumed to be equal to $u_{rest}$. The resulting output spikes of the LIF neuron are shown in D.</i><br /></center>\n"]},{"cell_type":"markdown","metadata":{"id":"2RaffpvYJaB_"},"source":["## Synaptic dynamics\n","The previous equation describes the dynamics at the level of the membrane of the neuron. But also synapses may have their own dynamics, describing how a **post-synaptic current** $i(t)$ evolves in time in response to input spike trains:\n","\n","$$\\tau_s \\cdot d{i}/dt = - i(t) + \\sum_i w_i \\cdot \\sum_j \\delta(t-t_j^{i})$$\n","\n","where $\\sum_j \\delta(t-t_j^i)$ is a stream of spikes from presynaptic neuron $i$ occurring at times $t_j^i$ and the values $w_i$ represent the corresponding weights. In the absence of new input spikes, the synaptic current decays towards zero under the synaptic time constant $\\tau_s$. From this equation it is clear that the post-synaptic current is obtained by low-pass filtering the incoming spike trains. The resulting evolution of the post-synaptic current follows the well-known $\\alpha$-function so that this model of synaptic dynamics is sometimes also referred as $\\alpha$-synapse. Its behavior is shown in panel B of the previous figure."]},{"cell_type":"markdown","metadata":{"id":"nGDZ9FayfV9C"},"source":["## Spike generation\n","\n","The output of the LIF neuron is binary and instantaneous. It is $1$ only when $u$ reaches a *threshold* value $u_{th}$, upon which the membrane potential is immediately *reset* to $u_{reset}$. Frequently, the resting value $u_{rest}$ of the membrane potential can be used as the reset value. The instantaneous output is typically referred to as a *spike* at time $t$. A series of such spikes, i.e. the output **spike train** of the neuron, will hence forth be referred to as $s(t)$.\n","\n","$$\n","u(t+\\delta t) = \n","\\begin{cases}\n","u_{reset},& \\text{if } u(t) \\geq u_{th} \\\\ \n","u(t),& \\text{otherwise} \n","\\end{cases}\n","$$\n","\n","\n","$$\n","s(t) = \n","\\begin{cases}\n","1,& \\text{if } u(t)\\geq u_{th}\\\\\n","0,& \\text{otherwise}\n","\\end{cases}\n","$$\n","\n","When the spike generation mechanism is taken into account, the evolution of the membrane voltage undergoes immediate resets every time the threshold is crossed, as shown in panel C of the figure above in the case of strong-enough inputs. The resulting spiking activity is shown in panel D.\n"]},{"cell_type":"markdown","metadata":{"id":"f_hYS-MBNQol"},"source":["## Simulate the LIF neuron\n","\n","Let's simulate a LIF neuron from scratch using Python basic packages. We will give to it a random spike train as input and visualize the evolution of its internal variables, as well as its output spiking activity, in time."]},{"cell_type":"markdown","metadata":{"id":"ckIPFLsDUXCZ"},"source":["#### **Generate an input activity**\n","\n","First of all, we should set the simulation parameters (i.e. total duration and time-step) and then generate a random (\"Poisson\") spike train by thresholding random noise. We will use a $10$% firing probability."]},{"cell_type":"code","metadata":{"id":"XrSc2yM0ger1"},"source":["# --> Import some useful packages\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aajotBQpNUHa"},"source":["# --> Generate a random spike train\n","\n","# Define simulation time-step and duration\n","dt = 1                                        # Time-setp (ms)\n","T = 100                                       # Total duration (ms)\n","N = int(round(T/dt))                          # Number of samples\n","times = np.linspace(0, T, N, endpoint=False)  # Array of times\n","\n","# Generate a random spike train: we will have a spike every time a randomly-extracted\n","# number (with uniform distribution from range [0, 1]) is smaller than spike_prob\n","np.random.seed(3)\n","spike_prob = 0.1\n","spikes_in = np.random.rand(N,) < spike_prob\n","spike_times_in = times[np.argwhere(spikes_in)].flatten()\n","\n","# Plot the spike train\n","plt.figure(figsize=(7, 4))\n","markerline, stemlines, baseline = plt.stem(times, spikes_in, use_line_collection=True, basefmt='C0')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(3)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.title('Input Random Spike-Train', fontsize=16)\n","plt.ylim(-.2, 4)\n","plt.yticks([], [])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Wmif5sVNgMg"},"source":["#### **Solve differential equations**\n","Now that we have a pre-synaptic spiking activity, let's see how the membrane potential $u(t)$ and the synaptic current $i(t)$ of the post-synaptic LIF neuron evolve in time. To do so, we implement the synaptic and membrane dynamics by iterating over time and compute their values in the simplest possible way. We will also include spike generation in the simulation, by resetting the membrane voltage every time it reaches the threshold value, and show the resulting output spike train of our neuron. We will *not* consider other possible mechanisms interfering with the these dynamics, such as *refractory*.\n","\n","Note that, in order to deal with variables having all the same dimensions (same unit of measurement), instead of the sinaptic current we will consider the *synaptic potential* (which we will call $u_s(t)$). These two variables are directly related to each other by the following relationship: $u_s(t) = R \\cdot i(t)$. In this case, the synaptic weight $w$ (which we will now call $w_s$) will also have voltage units."]},{"cell_type":"code","metadata":{"id":"R_yng_qYWsjK"},"source":["# --> A simple Euler solver for synapse and membrane integration\n","\n","# Neuron and synapse parameters\n","tau_m = 10        # Membrane time constant (ms)\n","tau_s = 10        # Synaptic time constant (ms)\n","u_rest = -70      # Resting potential (mV)\n","u_th = -50        # Threshold for spike generation (mV)\n","u_reset = u_rest  # Reset potential (mV)\n","w_s = 22          # Synaptic weight (mV)\n","\n","# Initialization\n","u = u_rest        # Initialize membrane potential\n","u_s = 0           # Initialize synaptic potential\n","\n","# Create variables for storing data\n","u_t = np.zeros_like(times)\n","u_s_t = np.zeros_like(times)\n","spikes_out = np.zeros_like(times)\n","spike_times_out = []\n","\n","# Loop over time and solve the synapse and membrane dynamics\n","for k in range(N):\n","\n","    # 1) Synaptic dynamics integration\n","    du_s = - u_s / tau_s + w_s * spikes_in[k]\n","    u_s += du_s\n","    \n","    # 2) Membrane dynamics integration\n","    du = - (u - u_rest - u_s) / tau_m\n","    u += du\n","\n","    # 3) Spike generation\n","    if u >= u_th:\n","\n","      # Reset membrane potential\n","      u = u_reset  \n","\n","      # Save output spikes\n","      spikes_out[k] = 1\n","      spike_times_out.append(times[k])\n","    \n","    # Save synapse and membrane state evolution\n","    u_t[k] = u\n","    u_s_t[k] = u_s\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Y3_L36XZfBd"},"source":["# --> Plot membrane and synaptic states' evolution and input/output spikes\n","\n","plt.figure(figsize=(7, 15))\n","plt.subplot(311)\n","plt.plot(times, u_s_t, c='orange', label='Synaptic Potential')\n","markerline, stemlines, baseline = plt.stem(times, spikes_in * 0.1 * (u_s_t.max() - u_s_t.min()), use_line_collection=True, basefmt='C0', label='Input Spikes')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(2)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.ylabel('$u_s(t)$ [mV]', fontsize=13)\n","plt.title('Post-Synaptic Potential $u_s(t)$', fontsize=16)\n","plt.legend()\n","\n","plt.subplot(312)\n","plt.plot(times, u_t, c='red', label='Membrane Potential')\n","plt.plot([0, T], [u_th, u_th], 'k:', label='Spiking Threshold')\n","markerline, stemlines, baseline = plt.stem(times, u_reset + spikes_in * 0.1 * (u_t.max() - u_t.min()), use_line_collection=True, basefmt='C0', bottom=u_reset, label='Input Spikes')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(2)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.ylabel('$u(t)$ [mV]', fontsize=13)\n","plt.title('Membrane Potential $u(t)$', fontsize=16)\n","plt.legend()\n","\n","plt.subplot(313)\n","markerline, stemlines, baseline = plt.stem(times, spikes_out, use_line_collection=True, basefmt='k', linefmt='-k')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(4)\n","plt.ylim(-.2, 4)\n","plt.yticks([], [])\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.title('Spiking Activity $s(t)$', fontsize=16)\n","plt.subplots_adjust(hspace=0.3)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pcum24ZRVu-4"},"source":["# **3. Spiking Networks on Brian2**"]},{"cell_type":"markdown","metadata":{"id":"R53pKbYl35b5"},"source":["## Why Brian2?\n","\n","\n","\n","Brian2 is a simulator for spiking neural networks written in Python programming language. It became so popular in the neuroscience community that is now considered a benchmark for building and running SNNs. It is a very powerful tool as it allows to simulate complex neural networks in a simple and intuitive framework, leaving room to many possible variations you want to introduce in the models, therefore being flexible and easily extensible.\n","<img src=\"https://brian2.readthedocs.io/en/stable/_static/brian-logo.png\" width=200, align='right'>\n","It also allows, through specific backends, to run simuations on graphic cards, thus accelerating them by exploiting the computational power of high performance GPUs. Also, specific packages have been built on top of brian2 to implement SNNs on dedicated neuromorphic hardware: an example of this is *teili*, a toolbox providing neuromorphic engineers with a playground for implementing neural algorithms, as well as an interface with the DYNAPse neuromorphic processor. Other Python packages providing an interface to neuromorphic hardware are *PyNN*, which allows sending large-scale networks on spiking processors (such as Spinnaker or BrainScales) remotely via cloud, or *Nengo*, which carries an API for Intel’s neuromorphic Loihi chip.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3Gjm4lnIBPkI"},"source":["## Using Brian2\n","\n","The Brian2 library implements and provides a set of specific classes and methods for generating spiking neural networks and running simulations. The basic steps for building a network are:\n","\n","1. Establish the time-step\n","1. Create the neural populations\n","1. Create the connections (synapses) between the populations\n","1. Setup data monitoring\n","1. Build the network object and feed it with neural populations, synapses and monitors\n","1. Run the simulation\n","1. Retrieve and plot the recorded data\n","\n","**Read the documentation for more information on all the implemented objects:**  https://brian2.readthedocs.io/en/stable/\n","\n","\n","Thanks to the provided tools, we can re-write the previous example in a few lines of code:\n"]},{"cell_type":"code","metadata":{"id":"XnVU4Ro79ALT"},"source":["# --> Import brian2\n","# Note: unfortunately brian2 is not available by default on google colab.\n","# In order to use it we must therefore install it on the cloud every time we run\n","# a new notebook (but don't panic, nothing will be installed on your pc).\n","\n","!pip install brian2\n","from brian2 import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoenFtGA9yz5"},"source":["# --> Build the network and run the simulation\n","\n","# Define all the paramters for the simulation, giving them appropriate dimensions (!)\n","dt = 1 * ms\n","T = 100 * ms\n","tau_m = 10 * ms\n","tau_s = 10 * ms\n","u_th = -50 * mV\n","u_rest = -70 * mV\n","u_reset = -70 * mV\n","w_s = 22 * mV\n","\n","# ---------------- 1. Establish the time-step of the simulation ----------------\n","defaultclock.dt = dt\n","\n","# ---------------------- 2. Create the neural populations ----------------------\n","# Generate an input neuron group with 1 neuron and with the same spiking\n","# activity as the spike train randomly generated before\n","Neuron_input = SpikeGeneratorGroup(N=1, times=(spike_times_in) * ms,\n","                                   indices=np.zeros_like(spike_times_in)) \n","# Define the neural model specifying differential equations for the dynamics.\n","# Note that we put u_s in place of Ri in the equation describing the evolution of u\n","# (for the reasons discussed above) and we do not put the sum of all input spike-trains\n","# in the equation of the post-synaptic variable u_s (because we must update u_s\n","# with the input spikes at the pre-synaptic level: see the synapse object)\n","model = '''\n","du/dt = - (u - u_rest - u_s) / tau_m   : volt     # internal dynamics\n","du_s/dt = - u_s / tau_s                : volt     # synaptic dynamics\n","'''\n","# Create a neuron gruoup with 1 neuron, specify threshold and reset mechanisms,\n","# and the method to use for integrating the above equations\n","Neuron_output = NeuronGroup(N=1, model=model, threshold='u >= u_th',\n","                            reset='u = u_reset', method='euler')\n","Neuron_output.u = u_rest  # Initialize membrane potential\n","\n","# --------------------------- 3. Create the synapses ---------------------------\n","# Specify source and target populations of the synapse, the unit of measurement\n","# of the weight w and take account of the inconimg spikes at the pre-synaptic level\n","Syn = Synapses(source=Neuron_input, target=Neuron_output,\n","               model=\"\"\"w : volt\"\"\", on_pre='u_s += w')\n","Syn.connect()  # Actually connect the neurons (you can specifiy the connectvity)\n","Syn.w = w_s  # Set the synaptic weight\n","\n","# -------------------------- 4. Setup data monitoring --------------------------\n","# Monitor the input and output spikes, the membrane voltage u and the\n","# post-synaptic potential u_s\n","Mon_spikes_out = SpikeMonitor(source=Neuron_output)\n","Mon_u = StateMonitor(source=Neuron_output, variables=['u', 'u_s'], record=True)\n","\n","# -------------------- 5. Build and feed the network object --------------------\n","net = Network(Neuron_input, Neuron_output, Syn,\n","              Mon_u, Mon_spikes_out)\n","\n","# --------------------------- 6. Run the simulation ----------------------------\n","net.run(T, report='stdout')\n","\n","# ----------------------- 7. Retrieve the recorded data ------------------------\n","# Create arrays for membrane voltage and post-synaptic potential evolutions\n","u_t = Mon_u.u[0] / mV\n","u_s_t = Mon_u.u_s[0] / mV\n","# Create arrays of times\n","N = int(round(T/dt))\n","times = np.linspace(0, T / ms, N, endpoint=False)\n","# Create output spike-train arrays (put 1 when a spike is fired and 0 otherwise)\n","spike_times_out = Mon_spikes_out.t / ms\n","spikes_out = np.zeros_like(times)\n","for t in spike_times_out:\n","  spikes_out[times == t] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1PTxsl-B-kf"},"source":["# --> Plot membrane and synaptic states' evolution and input/output spikes\n","\n","plt.figure(figsize=(7, 15))\n","plt.subplot(311)\n","plt.plot(times, u_s_t, c='orange', label='Synaptic Potential')\n","markerline, stemlines, baseline = plt.stem(times, spikes_in * 0.1 * (u_s_t.max() - u_s_t.min()), use_line_collection=True, basefmt='C0', label='Input Spikes')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(2)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.ylabel('$u_s(t)$ [mV]', fontsize=13)\n","plt.title('Post-Synaptic Potential $u_s(t)$', fontsize=16)\n","plt.legend()\n","\n","plt.subplot(312)\n","plt.plot(times, u_t, c='red', label='Membrane Potential')\n","plt.plot([0, T / ms], [u_th / mV, u_th / mV], 'k:', label='Spiking Threshold')\n","markerline, stemlines, baseline = plt.stem(times, u_reset / mV + spikes_in * 0.1 * (u_t.max() - u_t.min()), use_line_collection=True, basefmt='C0', bottom=u_reset / mV, label='Input Spikes')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(2)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.ylabel('$u(t)$ [mV]', fontsize=13)\n","plt.title('Membrane Potential $u(t)$', fontsize=16)\n","plt.legend()\n","\n","plt.subplot(313)\n","markerline, stemlines, baseline = plt.stem(times, spikes_out, use_line_collection=True, basefmt='k', linefmt='-k')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(4)\n","plt.ylim(-.2, 4)\n","plt.yticks([], [])\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.title('Spiking Activity $s(t)$', fontsize=16)\n","plt.subplots_adjust(hspace=0.3)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vcai9bxu3YDY"},"source":["#### **Extension**\n","\n","- Try changing the code above by generating a Poisson input spike-train having same mean firing rate as the input spike-train previously considered (hint: use a \"*PoissonGroup*\" object instead of the \"*SpikeGeneratorGroup*\"), and add a refractory period of $10$ms to the output neuron (hint: you must put the 'unless refractory' flag in the neuron model). Then try increasing the firing rate of the Poisson group and see the effect of the refractory.\n","- Try changing some parametrs of the previous simulation (e.g. time constants, sign and value of the synaptic weight, etc.) and observe the resulting behavior."]},{"cell_type":"code","metadata":{"id":"CCycgfUg-PoW","cellView":"form"},"source":["#@title Double-click here for solution\n","\n","# Add the definition of refractory period!\n","tau_ref = 5 * ms\n","dt = 1 * ms\n","T = 100 * ms\n","tau_m = 10 * ms\n","tau_s = 10 * ms\n","u_th = -50 * mV\n","u_rest = -70 * mV\n","u_reset = -70 * mV\n","w_s = 22 * mV\n","\n","# ---------------- 1. Establish the time-step of the simulation ----------------\n","defaultclock.dt = dt\n","\n","# ---------------------- 2. Create the neural populations ----------------------\n","# Generate a Poisson neuron group with 1 neuron and firing rate equal to the one\n","# of the previously generated random spike-train\n","spike_rate_in = len(spike_times_in) / (T / ms * 10 ** -3) * Hz\n","Neuron_input = PoissonGroup(N=1, rates=spike_rate_in)\n","# Add the 'unless refractory' flag!\n","model = '''\n","du/dt = - (u - u_rest - u_s) / tau_m   : volt (unless refractory)\n","du_s/dt = - u_s / tau_s                : volt\n","'''\n","# Add the refractory mechanism to the neuron!\n","Neuron_output = NeuronGroup(N=1, model=model, threshold='u >= u_th',\n","                            reset='u = u_reset', refractory=tau_ref, method='euler')\n","Neuron_output.u = u_rest\n","\n","# --------------------------- 3. Create the synapses ---------------------------\n","Syn = Synapses(source=Neuron_input, target=Neuron_output,\n","               model=\"\"\"w : volt\"\"\", on_pre='u_s += w')\n","Syn.connect()\n","Syn.w = w_s\n","\n","# -------------------------- 4. Setup data monitoring --------------------------\n","# You should monitor also the input firing activity now!\n","Mon_spikes_in = SpikeMonitor(source=Neuron_input)\n","Mon_spikes_out = SpikeMonitor(source=Neuron_output)\n","Mon_u = StateMonitor(source=Neuron_output, variables=['u', 'u_s'], record=True)\n","\n","# -------------------- 5. Build and feed the network object --------------------\n","# Don't forget to add 'Mon_spike_in' to the network!\n","net = Network(Neuron_input, Neuron_output, Syn,\n","              Mon_spikes_in, Mon_u, Mon_spikes_out)\n","\n","# --------------------------- 6. Run the simulation ----------------------------\n","net.run(T)\n","\n","# ------------------ 7. Retrieve and plot the recorded data --------------------\n","u_t = Mon_u.u[0] / mV\n","u_s_t = Mon_u.u_s[0] / mV\n","N = int(round(T/dt))\n","times = np.linspace(0, T / ms, N, endpoint=False)\n","spike_times_out = Mon_spikes_out.t / ms\n","spikes_out = np.zeros_like(times)\n","for t in spike_times_out:\n","  spikes_out[times == t] = 1\n","# You should also create input spike-train arrays now!\n","spike_times_in = Mon_spikes_in.t / ms\n","spikes_in = np.zeros_like(times)\n","for t in spike_times_in:\n","  spikes_in[times == t] = 1\n","\n","# Plots\n","plt.figure(figsize=(7, 15))\n","plt.subplot(311)\n","plt.plot(times, u_s_t, c='orange', label='Synaptic Potential')\n","markerline, stemlines, baseline = plt.stem(times, spikes_in * 0.1 * (u_s_t.max() - u_s_t.min()), use_line_collection=True, basefmt='C0', label='Input Spikes')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(2)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.ylabel('$u_s(t)$ [mV]', fontsize=13)\n","plt.title('Post-Synaptic Potential $u_s(t)$', fontsize=16)\n","plt.legend()\n","\n","plt.subplot(312)\n","plt.plot(times, u_t, c='red', label='Membrane Potential')\n","plt.plot([0, T / ms], [u_th / mV, u_th / mV], 'k:', label='Spiking Threshold')\n","markerline, stemlines, baseline = plt.stem(times, u_reset / mV + spikes_in * 0.1 * (u_t.max() - u_t.min()), use_line_collection=True, basefmt='C0', bottom=u_reset / mV, label='Input Spikes')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(2)\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.ylabel('$u(t)$ [mV]', fontsize=13)\n","plt.title('Membrane Potential $u(t)$', fontsize=16)\n","plt.legend()\n","\n","plt.subplot(313)\n","markerline, stemlines, baseline = plt.stem(times, spikes_out, use_line_collection=True, basefmt='k', linefmt='-k')\n","markerline.set_marker(\"\")\n","stemlines.set_linewidth(4)\n","plt.ylim(-.2, 4)\n","plt.yticks([], [])\n","plt.xlabel('time [ms]', fontsize=13)\n","plt.title('Spiking Activity $s(t)$', fontsize=16)\n","plt.subplots_adjust(hspace=0.3)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V8ULMBQy8mQI"},"source":["# **4. Exercises**\n","The following exercises are designed to provide a hands-on introduction to Brian2 and enhance your understanding of SNNs. You should follow the step-by-step instructions in the linked notebooks.\n","\n"," - [Task 1: Synfire Chain](https://github.com/SimoNeT-Git/NC-ICT-class/blob/main/task1-SynfireChain.ipynb)\n","    - Create a **synfire chain** network from a single \"*NeuronGroup*\" of 100 inter-connected LIF neurons. Use a \"*SpikeGeneratorGroup*\" to stimulate the first neuron in the population at the start, thus triggering the resulting population dynamics. Record spikes and visualise a rasterplot (use \"*scatter*\" function from matplotlib.pyplot) of population activity after running the \"*Network*\" for 2 seconds.\n","    - See the notebook for further extensions.\n"," - [Task 2: Balanced Random Cortex-like Network](https://github.com/SimoNeT-Git/NC-ICT-class/blob/main/task2-BalancedRandomNet.ipynb)\n","    - Create a **balanced random network** consisting of one excitatory (E) and one inhibitory (I) \"*NeuronGroup*\" of LIF neurons, with a 4:1 E-I ratio and sparse reciprocal connectivity. The E population excites I and itself, while I inhibites E and itself. Extract weights and delays from normal distributions and use a different resting potential for each neuron taking it from a uniform distribution. Stimulate each neuron using a one-to-one connection from a \"*PoissonGroup*\" with rate 1000Hz. Run the \"*Network*\" for 1 second and visualise a rasterplot with all spikes from both populations.\n","    - See the notebook for further extensions.\n"," - [Task 3: Reichardt Detectors on Neuromorphic Sensor's Recordings](https://github.com/SimoNeT-Git/NC-ICT-class/blob/main/task3-ReichardtDetectors.ipynb)\n","    - Create a **Hassenstein-Reichardt detector** consisting of subsequent spatial and temporal filtering of the input spikes. Such input consists of event-based data recorded from the neuromorphic sensor. Code for the initial data loading and pre-processing is given and you will have to build the network for motion perception. The network is made of a \"*SpikeGeneratorGroup*\" for the input events and 3 populations of LIF neurons. The first \"*NeuronGroup*\" applies convolution on the input data (spatial filtering) while the other 2 groups set the delays (temporal filtering) in case of both rightward (R) and leftward (L) motion selectivity. Run the \"*Network*\" for 300ms. Visualise membrane potentials and spikes of the convolutional layer, and the resulting outputs of R and L detectors.\n","    - See the notebook for further extensions."]},{"cell_type":"markdown","metadata":{"id":"7UzsQ_0jh3qZ"},"source":["\n","\n","---\n","\n","\n","# References & End Notes\n","\n","Below I report some links to online material which you could find useful if interested on these topics and want to learn more:\n"," \n"," 1. For an exhaustive introduction and getting started with *Google Colaboratory* watch this [video](https://www.youtube.com/watch?v=inN8seMm7UI) and read this [notebook](https://colab.research.google.com/notebooks/intro.ipynb).\n","\n"," 2. For a comparison between Matlab and Python read this [article](https://realpython.com/matlab-vs-python/).\n","\n"," 3. For a very deep explanation of different neuron and synapse models read this [book](https://neuronaldynamics.epfl.ch/online/index.html) from computational neuroscientist *Wulfram Gerstner*, including [exercises](https://lcn-neurodynex-exercises.readthedocs.io/en/latest/), [notes](https://neuronaldynamics.epfl.ch/lectures.html) and [video lectures](https://lcnwww.epfl.ch/gerstner/NeuronalDynamics-MOOCall.html).\n","\n"," 4. For more information on *Brian2* Python library read the [documentation](https://brian2.readthedocs.io/en/stable/).\n","\n"," 5. For some exercises on SNN applications for AI see this [repository](https://github.com/synsense/snn-workshop-amld-2020/).\n","\n","#### Author: **Simone Testa**\n","\n","<u>Note</u>: the introduction to SNN was adapted from [this notebook](https://colab.research.google.com/github/ai-cortex/snn-workshop-amld-2020/blob/master/Notebooks/1_IntroToSNNs/1_IntroToSNNs.ipynb) by *Sadique Sheik* and *Dylan Muir* written for the AMLD 2020 workshop on using SNNs for low-power and real-time inference tasks, while exercises 1 and 2 were adapted from [material](http://spinnakermanchester.github.io/workshops/) provided during the workshop on using Spinnaker neuromorphic hardware held by *Andrew Rowley* in occasion of the 4<sup>th</sup> HBP student conference (Pisa, January 2020)."]}]}
